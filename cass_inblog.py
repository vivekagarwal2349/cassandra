# -*- coding: utf-8 -*-
"""cass..inblog.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HvjaaSHkITObQkIGuRRRerEk_1fllkDF
"""

# Commented out IPython magic to ensure Python compatibility.
#importing necessary libraries
import pandas as pd
import numpy as np


import matplotlib.pyplot as plt
import seaborn as sns
# to show the figures in the jupyter notebook itself
# %matplotlib inline

train = pd.read_csv('/content/train.csv', parse_dates=['Date']) # loading the training data

# train.head()

train['Date'] = pd.DatetimeIndex(train['Date'])

train['Holiday'] = train['Holiday'].replace(['NO'], 0)
train['Holiday'] = train['Holiday'].replace(['YES'], 1)
train['Working Day'] = train['Working Day'].replace(['NO'], 0)
train['Working Day'] = train['Working Day'].replace(['YES'], 1)
train['Seasons'] = train['Seasons'].replace(['Summer'], 1)
train['Seasons'] = train['Seasons'].replace(['Winter'], 2)
train['Seasons'] = train['Seasons'].replace(['Spring'], 3)
train['Seasons'] = train['Seasons'].replace(['Autumn'], 4)

for i in range(0,len(train.Hour)) :
    train.Hour[i] = train.Hour[i][:-3]
train['Hour'] = train['Hour'].astype(str).astype(int)

# transforming dteday to day month and year
train['day'] = pd.DatetimeIndex(train['Date']).day
train['month'] = pd.DatetimeIndex(train['Date']).month
train['year'] = pd.DatetimeIndex(train['Date']).year
train['Weekday'] = pd.DatetimeIndex(train['Date']).dayofweek

train.drop(['id', 'Date', 'year', 'Wind Speed', 'Visibility', 'Solar Radiation'], axis=1, inplace=True)

# train.describe()

test = pd.read_csv('/content/test.csv')

test['Date'] = pd.DatetimeIndex(test['Date'])
test['Holiday'] = test['Holiday'].replace(['NO'], 0)
test['Holiday'] = test['Holiday'].replace(['YES'], 1)
test['Working Day'] = test['Working Day'].replace(['NO'], 0)
test['Working Day'] = test['Working Day'].replace(['YES'], 1)
test['Seasons'] = test['Seasons'].replace(['Summer'], 1)
test['Seasons'] = test['Seasons'].replace(['Winter'], 2)
test['Seasons'] = test['Seasons'].replace(['Spring'], 3)
test['Seasons'] = test['Seasons'].replace(['Autumn'], 4)
for i in range(0,len(test.Hour)) :
    test.Hour[i] = test.Hour[i][:-3]
test['Hour'] = test['Hour'].astype(str).astype(int)
# transforming dteday to day month and year
test['day'] = pd.DatetimeIndex(test['Date']).day
test['month'] = pd.DatetimeIndex(test['Date']).month
test['year'] = pd.DatetimeIndex(test['Date']).year
test['Weekday'] = pd.DatetimeIndex(test['Date']).dayofweek
test.drop(['id', 'Date', 'year', 'Wind Speed', 'Visibility', 'Solar Radiation'], axis=1, inplace=True)
# test.describe()

# ! pip install -U pandas-profiling

# ! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip

# import pandas_profiling
# train.profile_report()

# splitting to testing and training datasets
train_dataset = train.sample(frac=0.8,random_state=0)
test_dataset = train.drop(train_dataset.index)

train_stats = train_dataset.describe()
train_stats.pop("Count")
train_stats = train_stats.transpose()
train_stats

train_labels = train_dataset.pop('Count')
test_labels = test_dataset.pop('Count')

# normalization of dataset
def norm(x):
    return (x - train_stats['mean']) / train_stats['std']

normed_train_data = norm(train_dataset)
normed_test_data = norm(test_dataset)

from tensorflow.keras import backend as K

def root_mean_squared_error(y_true, y_pred):
        return K.sqrt(K.mean(K.square(y_pred - y_true)))
    
def rmsle(y, y0):
        return K.sqrt(K.mean(K.square(tf.math.log1p(y) - tf.math.log1p(y0))))

def build_model():
    model = keras.Sequential([
        layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),
        layers.Dense(64, activation='relu'),
        layers.Dense(1, kernel_constraint=tf.keras.constraints.NonNeg())
    ])

    optimizer = tf.keras.optimizers.RMSprop(0.001)

    model.compile(loss=root_mean_squared_error,
                optimizer=optimizer,
                metrics=[root_mean_squared_error, rmsle,'mae', 'mse'])

    return model

import pathlib

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
# !pip install -q git+https://github.com/tensorflow/docs 
import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling

model = build_model()
model.summary()

# normed_train_data.dtypes
normed_train_data = np.asarray(normed_train_data).astype('float32')
train_labels = np.asarray(train_labels).astype('float32')
normed_test_data = np.asarray(normed_test_data).astype('float32')
test_labels = np.asarray(test_labels).astype('float32')

tf.config.run_functions_eagerly(True)

EPOCHS = 1000

history = model.fit(
  normed_train_data, train_labels,
  epochs=EPOCHS, validation_split = 0.2, verbose=0,
  callbacks=[tfdocs.modeling.EpochDots()])

# history of loss and metrics
hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)

# plotter.plot({'Basic': history}, metric = "loss")

normed_original_test_data = norm(test)
original_test_predictions = model.predict(normed_original_test_data).flatten()
output=pd.DataFrame()
original_test = pd.read_csv('/content/test.csv')

output['id'] = original_test['id']
output['Count'] = original_test_predictions
output.to_csv('/content/output3.csv', index=False)
